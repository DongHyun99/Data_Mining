{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ee6caf572b02fbd90c9d9a82b73a7abd542127d236c55761b702f851ee4a295f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2. DBSCAN으로 학습하기 (cancer)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "\n",
    "iris = load_breast_cancer()\n",
    "\n",
    "iris.data = pd.DataFrame(iris.data)\n",
    "iris.target = pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\neps의 값은 항상 positive 해야 하므로 for문에 넣을 수 없다.\\n따라서 계획 했던대로 eps의 값을 증가 시켜보며 학습하는 것은 힘들고\\nminpts의 값을 증가시키면서 학습해보겠다.\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Specify the eps value\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "'''\n",
    "eps의 값은 항상 positive 해야 하므로 for문에 넣을 수 없다.\n",
    "따라서 계획 했던대로 eps의 값을 증가 시켜보며 학습하는 것은 힘들고\n",
    "minpts의 값을 증가시키면서 학습해보겠다.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      0\n0     0\n1   569\n2     1\n3     1\n4     1\n..  ...\n95    1\n96    1\n97    1\n98    1\n99    1\n\n[100 rows x 1 columns]\nEmpty DataFrame\nColumns: [0]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "# class count graph with minpts change\n",
    "# min_samples는 1~100까지 돌려본다.\n",
    "\n",
    "class_count=[0,]\n",
    "\n",
    "for i in range(1,100,1):\n",
    "    dbscan = DBSCAN(min_samples=i)\n",
    "    result = dbscan.fit_predict(iris.data)\n",
    "    class_count.append(len(np.unique(result)))\n",
    "\n",
    "class_count = pd.DataFrame(class_count)\n",
    "print(class_count)\n",
    "class_count = class_count[class_count[0]==2]\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_iris_dbscan accuracy\n",
    "# class의 개수가 데이터의 개수와 맞는 것의 accuracy를 측정해본다.\n",
    "\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "for i in class_count.index:\n",
    "    dbscan = DBSCAN(min_samples=i)\n",
    "    result = dbscan.fit_predict(iris.data)\n",
    "    print('minpts=',i,\":\",normalized_mutual_info_score(iris.target[0], result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler Preprocessed DBSCAN Accuracy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "data_minmax = MinMaxScaler().fit_transform(iris.data)\n",
    "data_maxabs = MaxAbsScaler().fit_transform(iris.data)\n",
    "data_standard = StandardScaler().fit_transform(iris.data)\n",
    "data_robust = RobustScaler().fit_transform(iris.data)\n",
    "data_normalize = Normalizer().fit_transform(iris.data)\n",
    "data_log = np.log1p(iris.data)\n",
    "\n",
    "class_count_minmax, class_count_maxabs, class_count_standard, class_count_robust, class_count_normalize, class_count_log = [],[],[],[],[],[]\n",
    "\n",
    "for i in range(1,100,1):\n",
    "    dbscan = DBSCAN(min_samples=i)\n",
    "    result_minmax = dbscan.fit_predict(data_minmax)\n",
    "    result_maxabs = dbscan.fit_predict(data_maxabs)\n",
    "    result_standard = dbscan.fit_predict(data_standard)\n",
    "    result_robust = dbscan.fit_predict(data_robust)\n",
    "    result_normalize = dbscan.fit_predict(data_normalize)\n",
    "    result_log = dbscan.fit_predict(data_log)\n",
    "\n",
    "    class_count_minmax.append(len(np.unique(result_minmax)))\n",
    "    class_count_maxabs.append(len(np.unique(result_maxabs)))\n",
    "    class_count_standard.append(len(np.unique(result_standard)))\n",
    "    class_count_robust.append(len(np.unique(result_robust)))\n",
    "    class_count_normalize.append(len(np.unique(result_normalize)))\n",
    "    class_count_log.append(len(np.unique(result_log)))\n",
    "\n",
    "class_count_minmax = pd.DataFrame(class_count_minmax)\n",
    "class_count_minmax = class_count_minmax[class_count_minmax[0]==2]\n",
    "class_count_maxabs = pd.DataFrame(class_count_maxabs)\n",
    "class_count_maxabs = class_count_maxabs[class_count_maxabs[0]==2]\n",
    "class_count_standard = pd.DataFrame(class_count_standard)\n",
    "class_count_standard = class_count_standard[class_count_standard[0]==2]\n",
    "class_count_robust = pd.DataFrame(class_count_robust)\n",
    "class_count_robust = class_count_robust[class_count_robust[0]==2]\n",
    "class_count_normalize = pd.DataFrame(class_count_normalize)\n",
    "class_count_normalize = class_count_normalize[class_count_normalize[0]==2]\n",
    "class_count_log = pd.DataFrame(class_count_log)\n",
    "class_count_log = class_count_log[class_count_log[0]==2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_minmax, score_maxabs, score_standard, score_robust, score_normalize, score_log = [], [], [], [], [], []\n",
    "\n",
    "def minpts_score(arr, data, score_list):\n",
    "    for i in arr.index:\n",
    "        dbscan = DBSCAN(min_samples=i)\n",
    "        result = dbscan.fit_predict(data)\n",
    "        score_list.append(normalized_mutual_info_score(iris.target[0], result))\n",
    "\n",
    "minpts_score(class_count_minmax, data_minmax, score_minmax)\n",
    "minpts_score(class_count_maxabs, data_maxabs, score_maxabs)\n",
    "minpts_score(class_count_standard, data_standard, score_standard)\n",
    "minpts_score(class_count_robust, data_robust, score_robust)\n",
    "minpts_score(class_count_normalize, data_normalize, score_normalize)\n",
    "minpts_score(class_count_log, data_log, score_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax score: 0.3779583353349977\nmaxabs score: 0.235355760449808\nstandard score: 0\nrobust score: 0\nnormalize score: 0\nlog score: 0.2861761770353164\n"
     ]
    }
   ],
   "source": [
    "def not_value(string, value):\n",
    "    try:\n",
    "        print(string, max(value))\n",
    "    except ValueError:\n",
    "        print(string, 0)\n",
    "\n",
    "not_value('minmax score:', score_minmax)\n",
    "not_value('maxabs score:', score_maxabs)\n",
    "not_value('standard score:', score_standard)\n",
    "not_value('robust score:', score_robust)\n",
    "not_value('normalize score:', score_normalize)\n",
    "not_value('log score:', score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=2)\n",
    "\n",
    "data_minmax = MinMaxScaler().fit_transform(iris.data)\n",
    "data_maxabs = MaxAbsScaler().fit_transform(iris.data)\n",
    "data_standard = StandardScaler().fit_transform(iris.data)\n",
    "data_robust = RobustScaler().fit_transform(iris.data)\n",
    "data_normalize = Normalizer().fit_transform(iris.data)\n",
    "data_log = np.log1p(iris.data)\n",
    "\n",
    "data_minmax = model.fit_transform(data_minmax)\n",
    "data_maxabs = model.fit_transform(data_maxabs)\n",
    "data_standard = model.fit_transform(data_standard)\n",
    "data_robust = model.fit_transform(data_robust)\n",
    "data_normalize = model.fit_transform(data_normalize)\n",
    "data_log = model.fit_transform(data_log)\n",
    "\n",
    "class_count_minmax, class_count_maxabs, class_count_standard, class_count_robust, class_count_normalize, class_count_log = [],[],[],[],[],[]\n",
    "\n",
    "for i in range(1,100,1):\n",
    "    dbscan = DBSCAN(min_samples=i)\n",
    "    result_minmax = dbscan.fit_predict(data_minmax)\n",
    "    result_maxabs = dbscan.fit_predict(data_maxabs)\n",
    "    result_standard = dbscan.fit_predict(data_standard)\n",
    "    result_robust = dbscan.fit_predict(data_robust)\n",
    "    result_normalize = dbscan.fit_predict(data_normalize)\n",
    "    result_log = dbscan.fit_predict(data_log)\n",
    "\n",
    "    class_count_minmax.append(len(np.unique(result_minmax)))\n",
    "    class_count_maxabs.append(len(np.unique(result_maxabs)))\n",
    "    class_count_standard.append(len(np.unique(result_standard)))\n",
    "    class_count_robust.append(len(np.unique(result_robust)))\n",
    "    class_count_normalize.append(len(np.unique(result_normalize)))\n",
    "    class_count_log.append(len(np.unique(result_log)))\n",
    "\n",
    "class_count_minmax = pd.DataFrame(class_count_minmax)\n",
    "class_count_minmax = class_count_minmax[class_count_minmax[0]==2]\n",
    "class_count_maxabs = pd.DataFrame(class_count_maxabs)\n",
    "class_count_maxabs = class_count_maxabs[class_count_maxabs[0]==2]\n",
    "class_count_standard = pd.DataFrame(class_count_standard)\n",
    "class_count_standard = class_count_standard[class_count_standard[0]==2]\n",
    "class_count_robust = pd.DataFrame(class_count_robust)\n",
    "class_count_robust = class_count_robust[class_count_robust[0]==2]\n",
    "class_count_normalize = pd.DataFrame(class_count_normalize)\n",
    "class_count_normalize = class_count_normalize[class_count_normalize[0]==2]\n",
    "class_count_log = pd.DataFrame(class_count_log)\n",
    "class_count_log = class_count_log[class_count_log[0]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_minmax, score_maxabs, score_standard, score_robust, score_normalize, score_log = [], [], [], [], [], []\n",
    "\n",
    "def minpts_score(arr, data, score_list):\n",
    "    for i in arr.index:\n",
    "        dbscan = DBSCAN(min_samples=i)\n",
    "        result = dbscan.fit_predict(data)\n",
    "        score_list.append(normalized_mutual_info_score(iris.target[0], result))\n",
    "\n",
    "minpts_score(class_count_minmax, data_minmax, score_minmax)\n",
    "minpts_score(class_count_maxabs, data_maxabs, score_maxabs)\n",
    "minpts_score(class_count_standard, data_standard, score_standard)\n",
    "minpts_score(class_count_robust, data_robust, score_robust)\n",
    "minpts_score(class_count_normalize, data_normalize, score_normalize)\n",
    "minpts_score(class_count_log, data_log, score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax score: 0.08081436576456062\nmaxabs score: 0.04368888477914224\nstandard score: 0.29323954123530593\nrobust score: 0.3650997806501175\nnormalize score: 0\nlog score: 0.2919695853298047\n"
     ]
    }
   ],
   "source": [
    "def not_value(string, value):\n",
    "    try:\n",
    "        print(string, max(value))\n",
    "    except ValueError:\n",
    "        print(string, 0)\n",
    "\n",
    "not_value('minmax score:', score_minmax)\n",
    "not_value('maxabs score:', score_maxabs)\n",
    "not_value('standard score:', score_standard)\n",
    "not_value('robust score:', score_robust)\n",
    "not_value('normalize score:', score_normalize)\n",
    "not_value('log score:', score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "data_minmax = MinMaxScaler().fit_transform(iris.data)\n",
    "data_maxabs = MaxAbsScaler().fit_transform(iris.data)\n",
    "data_standard = StandardScaler().fit_transform(iris.data)\n",
    "data_robust = RobustScaler().fit_transform(iris.data)\n",
    "data_normalize = Normalizer().fit_transform(iris.data)\n",
    "data_log = np.log1p(iris.data)\n",
    "\n",
    "data_minmax = model.fit_transform(data_minmax)\n",
    "data_maxabs = model.fit_transform(data_maxabs)\n",
    "data_standard = model.fit_transform(data_standard)\n",
    "data_robust = model.fit_transform(data_robust)\n",
    "data_normalize = model.fit_transform(data_normalize)\n",
    "data_log = model.fit_transform(data_log)\n",
    "\n",
    "class_count_minmax, class_count_maxabs, class_count_standard, class_count_robust, class_count_normalize, class_count_log = [],[],[],[],[],[]\n",
    "\n",
    "for i in range(1,100,1):\n",
    "    dbscan = DBSCAN(min_samples=i)\n",
    "    result_minmax = dbscan.fit_predict(data_minmax)\n",
    "    result_maxabs = dbscan.fit_predict(data_maxabs)\n",
    "    result_standard = dbscan.fit_predict(data_standard)\n",
    "    result_robust = dbscan.fit_predict(data_robust)\n",
    "    result_normalize = dbscan.fit_predict(data_normalize)\n",
    "    result_log = dbscan.fit_predict(data_log)\n",
    "\n",
    "    class_count_minmax.append(len(np.unique(result_minmax)))\n",
    "    class_count_maxabs.append(len(np.unique(result_maxabs)))\n",
    "    class_count_standard.append(len(np.unique(result_standard)))\n",
    "    class_count_robust.append(len(np.unique(result_robust)))\n",
    "    class_count_normalize.append(len(np.unique(result_normalize)))\n",
    "    class_count_log.append(len(np.unique(result_log)))\n",
    "\n",
    "class_count_minmax = pd.DataFrame(class_count_minmax)\n",
    "class_count_minmax = class_count_minmax[class_count_minmax[0]==2]\n",
    "class_count_maxabs = pd.DataFrame(class_count_maxabs)\n",
    "class_count_maxabs = class_count_maxabs[class_count_maxabs[0]==2]\n",
    "class_count_standard = pd.DataFrame(class_count_standard)\n",
    "class_count_standard = class_count_standard[class_count_standard[0]==2]\n",
    "class_count_robust = pd.DataFrame(class_count_robust)\n",
    "class_count_robust = class_count_robust[class_count_robust[0]==2]\n",
    "class_count_normalize = pd.DataFrame(class_count_normalize)\n",
    "class_count_normalize = class_count_normalize[class_count_normalize[0]==2]\n",
    "class_count_log = pd.DataFrame(class_count_log)\n",
    "class_count_log = class_count_log[class_count_log[0]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_minmax, score_maxabs, score_standard, score_robust, score_normalize, score_log = [], [], [], [], [], []\n",
    "\n",
    "def minpts_score(arr, data, score_list):\n",
    "    for i in arr.index:\n",
    "        dbscan = DBSCAN(min_samples=i)\n",
    "        result = dbscan.fit_predict(data)\n",
    "        score_list.append(normalized_mutual_info_score(iris.target[0], result))\n",
    "\n",
    "minpts_score(class_count_minmax, data_minmax, score_minmax)\n",
    "minpts_score(class_count_maxabs, data_maxabs, score_maxabs)\n",
    "minpts_score(class_count_standard, data_standard, score_standard)\n",
    "minpts_score(class_count_robust, data_robust, score_robust)\n",
    "minpts_score(class_count_normalize, data_normalize, score_normalize)\n",
    "minpts_score(class_count_log, data_log, score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax score: 0\nmaxabs score: 0.12161013648092414\nstandard score: 0\nrobust score: 0\nnormalize score: 0.1879184492552643\nlog score: 0.09559606601586798\n"
     ]
    }
   ],
   "source": [
    "def not_value(string, value):\n",
    "    try:\n",
    "        print(string, max(value))\n",
    "    except ValueError:\n",
    "        print(string, 0)\n",
    "\n",
    "not_value('minmax score:', score_minmax)\n",
    "not_value('maxabs score:', score_maxabs)\n",
    "not_value('standard score:', score_standard)\n",
    "not_value('robust score:', score_robust)\n",
    "not_value('normalize score:', score_normalize)\n",
    "not_value('log score:', score_log)"
   ]
  }
 ]
}