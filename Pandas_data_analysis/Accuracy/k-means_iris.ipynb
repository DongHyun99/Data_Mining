{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ee6caf572b02fbd90c9d9a82b73a7abd542127d236c55761b702f851ee4a295f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. K-means로 학습하기 (iris)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris.data = pd.DataFrame(iris.data)\n",
    "iris.target = pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 반복하는 pipeline 함수 제작\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def pipe(model: Pipeline, train, target):\n",
    "    result = []\n",
    "    for i in range(0,10,1):\n",
    "        model.fit_transform(train, target)\n",
    "        result.append(model.predict(train))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7581756800057784\n"
     ]
    }
   ],
   "source": [
    "# normal_iris_kmeans accuracy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pipeline = Pipeline([('Kmeans', KMeans(n_clusters=3, init='random'))]) # normal predict 생성\n",
    "result_norm = pipe(pipeline, iris.data, iris.target)\n",
    "\n",
    "\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score # Adjusted rand score는 음수가 나올수 있으므로 백분율 계산을 위해서 Normalized mutual information을 사용했다. \n",
    "\n",
    "score = []\n",
    "for i in result_norm:\n",
    "    score.append(normalized_mutual_info_score(iris.target[0], i))\n",
    "\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax_pca: 0.7419116631817836\nmaxabs_pca: 0.8641855068202222\nstandard_pca: 0.6560030695993191\nrobust_pca: 0.6162206156967885\nnormalize_pca: 0.8996935451597474\nlog_scaled_pca: 0.8464828103876364\n"
     ]
    }
   ],
   "source": [
    "# PCA _iris_kemans accuracy\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# 각 정규화 된 값들을 PCA로 차원축소 시키고 값이 어떻게 변화하는지 살펴본다.\n",
    "# 일단 컴포넌트는 2로 하고 1~3중 어느값이 가장 좋은 결과를 가지는지 학습시켜본다.\n",
    "pipeline_minmax = Pipeline([('MinMax', MinMaxScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_maxabs = Pipeline([('MaxAbs', MaxAbsScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_standard = Pipeline([('Standard', StandardScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_robust = Pipeline([('Robust', RobustScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_normalize = Pipeline([('Normalize', Normalizer()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_log = Pipeline([('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "\n",
    "result_minmax = pipe(pipeline_minmax, iris.data, iris.target)\n",
    "result_maxabs = pipe(pipeline_maxabs, iris.data, iris.target)\n",
    "result_standard = pipe(pipeline_standard, iris.data, iris.target)\n",
    "result_robust = pipe(pipeline_robust, iris.data, iris.target)\n",
    "result_normalize = pipe(pipeline_normalize, iris.data, iris.target)\n",
    "result_log = pipe(pipeline_log, np.log1p(iris.data), iris.target)\n",
    "\n",
    "score_minmax, score_maxabs, score_standard, score_robust, score_normalize, score_log = [], [], [], [], [], []\n",
    "for i in range(0,10,1):\n",
    "    score_minmax.append(normalized_mutual_info_score(iris.target[0], result_minmax[i]))\n",
    "    score_maxabs.append(normalized_mutual_info_score(iris.target[0], result_maxabs[i]))\n",
    "    score_standard.append(normalized_mutual_info_score(iris.target[0], result_standard[i]))\n",
    "    score_robust.append(normalized_mutual_info_score(iris.target[0], result_robust[i]))\n",
    "    score_normalize.append(normalized_mutual_info_score(iris.target[0], result_normalize[i]))\n",
    "    score_log.append(normalized_mutual_info_score(iris.target[0], result_log[i]))\n",
    "\n",
    "print('minmax_pca:',np.mean(score_minmax))\n",
    "print('maxabs_pca:',np.mean(score_maxabs))\n",
    "print('standard_pca:',np.mean(score_standard))\n",
    "print('robust_pca:',np.mean(score_robust))\n",
    "print('normalize_pca:',np.mean(score_normalize))\n",
    "print('log_scaled_pca:',np.mean(score_log))\n",
    "\n",
    "# normalizer의 accuracy가 가장 높으므로 normalizer로 전처리된 값을 이용해 PCA의 컴포넌트를 1~3까지 넣어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "component=1: 0.9305506621576433\ncomponent=2: 0.8996935451597474\ncomponent=3: 0.8996935451597474\n"
     ]
    }
   ],
   "source": [
    "# PCA _iris_kemans accuracy (change_component)\n",
    "\n",
    "pipeline1 = Pipeline([('Normalize', Normalizer()),('PCA', PCA(n_components=1)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline2 = Pipeline([('Normalize', Normalizer()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline3 = Pipeline([('Normalize', Normalizer()),('PCA', PCA(n_components=3)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "\n",
    "result1 = pipe(pipeline1, iris.data, iris.target)\n",
    "result2 = pipe(pipeline2, iris.data, iris.target)\n",
    "result3 = pipe(pipeline3, iris.data, iris.target)\n",
    "\n",
    "score1, score2, score3 = [], [], []\n",
    "\n",
    "for i in range(0,10,1):\n",
    "    score1.append(normalized_mutual_info_score(iris.target[0], result1[i]))\n",
    "    score2.append(normalized_mutual_info_score(iris.target[0], result2[i]))\n",
    "    score3.append(normalized_mutual_info_score(iris.target[0], result3[i]))\n",
    "\n",
    "print('component=1:',np.mean(score1))\n",
    "print('component=2:',np.mean(score2))\n",
    "print('component=3:',np.mean(score3))\n",
    "\n",
    "# component는 1개일 때 가장 좋은 결과를 보였다. 다만 dataset 마다 결과는 다를 것으로보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE는 predict가 없기 때문에 pipeline에 넣을 경우 오류가 생긴다. 따라서 이를 우회해줄 TSNE Handler 함수를 만든다. (https://data-newbie.tistory.com/568)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TSNEHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,n_components=2, random_state=0): # randomstate는 0으로 고정해서 결과값을 통일한다.\n",
    "        self.tsne =TSNE(n_components=n_components, random_state = random_state, method=\"exact\")\n",
    "    \n",
    "    def fit(self,x):\n",
    "        self.tsne.fit(x)\n",
    "        \n",
    "    def transform(self,x):\n",
    "        x = self.tsne.fit_transform(x)\n",
    "        return x\n",
    "        \n",
    "    def fit_transform(self,x,y):\n",
    "        x = self.tsne.fit_transform(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax_TSNE: 0.8308354550894079\nmaxabs_TSNE: 0.8801106732223011\nstandard_TSNE: 0.6890518004413541\nrobust_TSNE: 0.6011685500834878\nnormalize_TSNE: 0.9143625311853999\nlog_scaled_TSNE: 0.8224038248765035\n"
     ]
    }
   ],
   "source": [
    "# TSNE_iris_kmeans accuracy\n",
    "# TSNE의 경우 코드 실행에 시간이 오래 걸리므로 한번의 학습만 실행\n",
    "\n",
    "pipeline_minmax = Pipeline([('MinMax', MinMaxScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_maxabs = Pipeline([('MaxAbs', MaxAbsScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_standard = Pipeline([('Standard', StandardScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_robust = Pipeline([('Robust', RobustScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_normalize = Pipeline([('Normalize', Normalizer()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline_log = Pipeline([('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "\n",
    "result_minmax = pipeline_minmax.fit_predict(iris.data, iris.target)\n",
    "result_maxabs = pipeline_maxabs.fit_predict(iris.data, iris.target)\n",
    "result_standard = pipeline_standard.fit_predict(iris.data, iris.target)\n",
    "result_robust = pipeline_robust.fit_predict(iris.data, iris.target)\n",
    "result_normalize = pipeline_normalize.fit_predict(iris.data, iris.target)\n",
    "result_log = pipeline_log.fit_predict(iris.data, iris.target)\n",
    "\n",
    "score_minmax = normalized_mutual_info_score(iris.target[0], result_minmax)\n",
    "score_maxabs = normalized_mutual_info_score(iris.target[0], result_maxabs)\n",
    "score_standard = normalized_mutual_info_score(iris.target[0], result_standard)\n",
    "score_robust = normalized_mutual_info_score(iris.target[0], result_robust)\n",
    "score_normalize = normalized_mutual_info_score(iris.target[0], result_normalize)\n",
    "score_log = normalized_mutual_info_score(iris.target[0], result_log)\n",
    "\n",
    "print('minmax_TSNE:',score_minmax)\n",
    "print('maxabs_TSNE:',score_maxabs)\n",
    "print('standard_TSNE:',score_standard)\n",
    "print('robust_TSNE:',score_robust)\n",
    "print('normalize_TSNE:',score_normalize)\n",
    "print('log_scaled_TSNE:',score_log)\n",
    "\n",
    "# 이번에도 normalizer의 accuracy가 가장 높다. normalizer로 전처리된 값을 이용해 TSNE의 컴포넌트를 1~3까지 넣어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "component=1: 0.6893972106394545\ncomponent=2: 0.9143625311853999\ncomponent=3: 0.6169066661909619\n"
     ]
    }
   ],
   "source": [
    "# TSNE_iris_kemans accuracy (change_component)\n",
    "\n",
    "pipeline1 = Pipeline([('Normalize', Normalizer()),('t-SNE', TSNEHandler(n_components=1, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline2 = Pipeline([('Normalize', Normalizer()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "pipeline3 = Pipeline([('Normalize', Normalizer()),('t-SNE', TSNEHandler(n_components=3, random_state=0)),('Kmeans', KMeans(n_clusters=3, init='random'))])\n",
    "\n",
    "result1 = pipeline1.fit_predict(iris.data, iris.target)\n",
    "result2 = pipeline2.fit_predict(iris.data, iris.target)\n",
    "result3 = pipeline3.fit_predict(iris.data, iris.target)\n",
    "\n",
    "score1 = normalized_mutual_info_score(iris.target[0], result1)\n",
    "score2 = normalized_mutual_info_score(iris.target[0], result2)\n",
    "score3 = normalized_mutual_info_score(iris.target[0], result3)\n",
    "\n",
    "print('component=1:',score1)\n",
    "print('component=2:',score2)\n",
    "print('component=3:',score3)\n",
    "\n",
    "# 이번에는 PCA와 다르게 component가 2일 때 가장 좋은 결과를 보여줬다."
   ]
  }
 ]
}