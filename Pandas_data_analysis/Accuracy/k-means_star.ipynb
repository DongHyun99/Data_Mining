{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ee6caf572b02fbd90c9d9a82b73a7abd542127d236c55761b702f851ee4a295f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. K-means로 학습하기 (iris)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-3-023e802f52b9>:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  iris.data = pd.read_csv(\"dataset/Stars.csv\")\n<ipython-input-3-023e802f52b9>:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  iris.target = pd.DataFrame(iris.data.Type)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0              1          2      3\n",
       "0     3068       0.002400     0.1700  16.12\n",
       "1     3042       0.000500     0.1542  16.60\n",
       "2     2600       0.000300     0.1020  18.70\n",
       "3     2800       0.000200     0.1600  16.65\n",
       "4     1939       0.000138     0.1030  20.06\n",
       "..     ...            ...        ...    ...\n",
       "235  38940  374830.000000  1356.0000  -9.93\n",
       "236  30839  834042.000000  1194.0000 -10.63\n",
       "237   8829  537493.000000  1423.0000 -10.73\n",
       "238   9235  404940.000000  1112.0000 -11.23\n",
       "239  37882  294903.000000  1783.0000  -7.80\n",
       "\n",
       "[240 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3068</td>\n      <td>0.002400</td>\n      <td>0.1700</td>\n      <td>16.12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3042</td>\n      <td>0.000500</td>\n      <td>0.1542</td>\n      <td>16.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2600</td>\n      <td>0.000300</td>\n      <td>0.1020</td>\n      <td>18.70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2800</td>\n      <td>0.000200</td>\n      <td>0.1600</td>\n      <td>16.65</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1939</td>\n      <td>0.000138</td>\n      <td>0.1030</td>\n      <td>20.06</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>38940</td>\n      <td>374830.000000</td>\n      <td>1356.0000</td>\n      <td>-9.93</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>30839</td>\n      <td>834042.000000</td>\n      <td>1194.0000</td>\n      <td>-10.63</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>8829</td>\n      <td>537493.000000</td>\n      <td>1423.0000</td>\n      <td>-10.73</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>9235</td>\n      <td>404940.000000</td>\n      <td>1112.0000</td>\n      <td>-11.23</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>37882</td>\n      <td>294903.000000</td>\n      <td>1783.0000</td>\n      <td>-7.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# data load\n",
    "iris=pd.DataFrame(['data','target'])\n",
    "iris.data = pd.read_csv(\"dataset/Stars.csv\")\n",
    "iris.target = pd.DataFrame(iris.data.Type)\n",
    "iris.data = iris.data.drop(['Color', 'Spectral_Class', 'Type'], axis=1)\n",
    "iris.data.columns=[0,1,2,3]\n",
    "iris.target.columns = [0]\n",
    "\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 반복하는 pipeline 함수 제작\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def pipe(model: Pipeline, train, target):\n",
    "    result = []\n",
    "    for i in range(0,10,1):\n",
    "        model.fit(train, target)\n",
    "        result.append(model.predict(train))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4526822938224745\n"
     ]
    }
   ],
   "source": [
    "# normal_iris_kmeans accuracy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pipeline = Pipeline([('Kmeans', KMeans(n_clusters=6, init='random'))]) # normal predict 생성\n",
    "result_norm = pipe(pipeline, iris.data, iris.target)\n",
    "\n",
    "\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score # Adjusted rand score는 음수가 나올수 있으므로 백분율 계산을 위해서 Normalized mutual information을 사용했다. \n",
    "\n",
    "score = []\n",
    "for i in result_norm:\n",
    "    score.append(normalized_mutual_info_score(iris.target[0], i))\n",
    "\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax_pca: 0.652067752432415\nmaxabs_pca: 0.6673590929856366\nstandard_pca: 0.6146000856528693\nrobust_pca: 0.5676579450235579\nnormalize_pca: 0.50691656893753\n"
     ]
    }
   ],
   "source": [
    "# PCA _iris_kemans accuracy\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# 각 정규화 된 값들을 PCA로 차원축소 시키고 값이 어떻게 변화하는지 살펴본다.\n",
    "# 일단 컴포넌트는 2로 하고 1~3중 어느값이 가장 좋은 결과를 가지는지 학습시켜본다.\n",
    "pipeline_minmax = Pipeline([('MinMax', MinMaxScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_maxabs = Pipeline([('MaxAbs', MaxAbsScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_standard = Pipeline([('Standard', StandardScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_robust = Pipeline([('Robust', RobustScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_normalize = Pipeline([('Normalize', Normalizer()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "\n",
    "result_minmax = pipe(pipeline_minmax, iris.data, iris.target)\n",
    "result_maxabs = pipe(pipeline_maxabs, iris.data, iris.target)\n",
    "result_standard = pipe(pipeline_standard, iris.data, iris.target)\n",
    "result_robust = pipe(pipeline_robust, iris.data, iris.target)\n",
    "result_normalize = pipe(pipeline_normalize, iris.data, iris.target)\n",
    "\n",
    "score_minmax, score_maxabs, score_standard, score_robust, score_normalize = [], [], [], [], []\n",
    "for i in range(0,10,1):\n",
    "    score_minmax.append(normalized_mutual_info_score(iris.target[0], result_minmax[i]))\n",
    "    score_maxabs.append(normalized_mutual_info_score(iris.target[0], result_maxabs[i]))\n",
    "    score_standard.append(normalized_mutual_info_score(iris.target[0], result_standard[i]))\n",
    "    score_robust.append(normalized_mutual_info_score(iris.target[0], result_robust[i]))\n",
    "    score_normalize.append(normalized_mutual_info_score(iris.target[0], result_normalize[i]))\n",
    "\n",
    "print('minmax_pca:',np.mean(score_minmax))\n",
    "print('maxabs_pca:',np.mean(score_maxabs))\n",
    "print('standard_pca:',np.mean(score_standard))\n",
    "print('robust_pca:',np.mean(score_robust))\n",
    "print('normalize_pca:',np.mean(score_normalize))\n",
    "\n",
    "# star data는 -값을 가져  log scaling을 할 수 없다.\n",
    "# normalizer의 accuracy가 가장 높으므로 maxabs로 전처리된 값을 이용해 PCA의 컴포넌트를 1~3까지 넣어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "component=1: 0.7812379025086349\ncomponent=2: 0.6511613762232875\ncomponent=3: 0.6896281627376561\n"
     ]
    }
   ],
   "source": [
    "# PCA _iris_kemans accuracy (change_component)\n",
    "\n",
    "pipeline1 = Pipeline([('MaxAbs', MaxAbsScaler()),('PCA', PCA(n_components=1)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline2 = Pipeline([('MaxAbs', MaxAbsScaler()),('PCA', PCA(n_components=2)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline3 = Pipeline([('MaxAbs', MaxAbsScaler()),('PCA', PCA(n_components=3)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "\n",
    "result1 = pipe(pipeline1, iris.data, iris.target)\n",
    "result2 = pipe(pipeline2, iris.data, iris.target)\n",
    "result3 = pipe(pipeline3, iris.data, iris.target)\n",
    "\n",
    "score1, score2, score3 = [], [], []\n",
    "\n",
    "for i in range(0,10,1):\n",
    "    score1.append(normalized_mutual_info_score(iris.target[0], result1[i]))\n",
    "    score2.append(normalized_mutual_info_score(iris.target[0], result2[i]))\n",
    "    score3.append(normalized_mutual_info_score(iris.target[0], result3[i]))\n",
    "\n",
    "print('component=1:',np.mean(score1))\n",
    "print('component=2:',np.mean(score2))\n",
    "print('component=3:',np.mean(score3))\n",
    "\n",
    "# component는 1개일 때 가장 좋은 결과를 보였다. 다만 dataset 마다 결과는 다를 것으로보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE는 predict가 없기 때문에 pipeline에 넣을 경우 오류가 생긴다. 따라서 이를 우회해줄 TSNE Handler 함수를 만든다. (https://data-newbie.tistory.com/568)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TSNEHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,n_components=2, random_state=0): # randomstate는 0으로 고정해서 결과값을 통일한다.\n",
    "        self.tsne =TSNE(n_components=n_components, random_state = random_state, method=\"exact\")\n",
    "    \n",
    "    def fit(self,x):\n",
    "        self.tsne.fit(x)\n",
    "        \n",
    "    def transform(self,x):\n",
    "        x = self.tsne.fit_transform(x)\n",
    "        return x\n",
    "        \n",
    "    def fit_transform(self,x,y):\n",
    "        x = self.tsne.fit_transform(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minmax_TSNE: 0.9335691044666057\nmaxabs_TSNE: 0.9415180988922823\nstandard_TSNE: 0.9386666362644679\nrobust_TSNE: 0.9514895154209181\nnormalize_TSNE: 0.6626632953103392\n"
     ]
    }
   ],
   "source": [
    "# TSNE_iris_kmeans accuracy\n",
    "# TSNE의 경우 코드 실행에 시간이 오래 걸리므로 한번의 학습만 실행\n",
    "\n",
    "pipeline_minmax = Pipeline([('MinMax', MinMaxScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_maxabs = Pipeline([('MaxAbs', MaxAbsScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_standard = Pipeline([('Standard', StandardScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_robust = Pipeline([('Robust', RobustScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline_normalize = Pipeline([('Normalize', Normalizer()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "\n",
    "result_minmax = pipeline_minmax.fit_predict(iris.data, iris.target)\n",
    "result_maxabs = pipeline_maxabs.fit_predict(iris.data, iris.target)\n",
    "result_standard = pipeline_standard.fit_predict(iris.data, iris.target)\n",
    "result_robust = pipeline_robust.fit_predict(iris.data, iris.target)\n",
    "result_normalize = pipeline_normalize.fit_predict(iris.data, iris.target)\n",
    "\n",
    "score_minmax = normalized_mutual_info_score(iris.target[0], result_minmax)\n",
    "score_maxabs = normalized_mutual_info_score(iris.target[0], result_maxabs)\n",
    "score_standard = normalized_mutual_info_score(iris.target[0], result_standard)\n",
    "score_robust = normalized_mutual_info_score(iris.target[0], result_robust)\n",
    "score_normalize = normalized_mutual_info_score(iris.target[0], result_normalize)\n",
    "\n",
    "print('minmax_TSNE:',score_minmax)\n",
    "print('maxabs_TSNE:',score_maxabs)\n",
    "print('standard_TSNE:',score_standard)\n",
    "print('robust_TSNE:',score_robust)\n",
    "print('normalize_TSNE:',score_normalize)\n",
    "\n",
    "# 이번에는 robust의 accuracy가 가장 높다. robust로 전처리된 값을 이용해 TSNE의 컴포넌트를 1~3까지 넣어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "component=1: 0.8979791562696023\ncomponent=2: 0.951489515420918\ncomponent=3: 0.5108186254766569\n"
     ]
    }
   ],
   "source": [
    "# TSNE_iris_kemans accuracy (change_component)\n",
    "\n",
    "pipeline1 = Pipeline([('Robust', RobustScaler()),('t-SNE', TSNEHandler(n_components=1, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline2 = Pipeline([('Robust', RobustScaler()),('t-SNE', TSNEHandler(n_components=2, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "pipeline3 = Pipeline([('Robust', RobustScaler()),('t-SNE', TSNEHandler(n_components=3, random_state=0)),('Kmeans', KMeans(n_clusters=6, init='random'))])\n",
    "\n",
    "result1 = pipeline1.fit_predict(iris.data, iris.target)\n",
    "result2 = pipeline2.fit_predict(iris.data, iris.target)\n",
    "result3 = pipeline3.fit_predict(iris.data, iris.target)\n",
    "\n",
    "score1 = normalized_mutual_info_score(iris.target[0], result1)\n",
    "score2 = normalized_mutual_info_score(iris.target[0], result2)\n",
    "score3 = normalized_mutual_info_score(iris.target[0], result3)\n",
    "\n",
    "print('component=1:',score1)\n",
    "print('component=2:',score2)\n",
    "print('component=3:',score3)\n",
    "\n",
    "# 이번에는 PCA와 다르게 component가 2일 때 가장 좋은 결과를 보여줬다."
   ]
  }
 ]
}